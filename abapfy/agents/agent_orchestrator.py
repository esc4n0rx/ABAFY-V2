from typing import Dict, Any, Callable
import time
from abapfy.agents.prompt_refiner import PromptRefinerAgent
from abapfy.agents.template_selector import TemplateSelectorAgent
from abapfy.agents.code_developer import CodeDeveloperAgent
from abapfy.agents.code_reviewer import CodeReviewerAgent
from abapfy.ai.client import AIClient
from abapfy.config.manager import ConfigManager
from abapfy.ui.colors import print_colored
from abapfy.utils.loading import LoadingContext, ProgressSpinner

class AgentOrchestrator:
    """Orquestrador dos agentes para geraÃ§Ã£o de cÃ³digo ABAP"""
    
    def __init__(self, ai_client: AIClient, config: ConfigManager):
        self.ai_client = ai_client
        self.config = config
        
        # Inicializar agentes
        self.agents = {
            "refiner": PromptRefinerAgent(ai_client, config),
            "selector": TemplateSelectorAgent(ai_client, config),
            "developer": CodeDeveloperAgent(ai_client, config),
            "reviewer": CodeReviewerAgent(ai_client, config)
        }
        
        # Pipeline de execuÃ§Ã£o
        self.pipeline_steps = [
            {
                "id": "refiner",
                "name": "ðŸ¤– Agente Refinador",
                "description": "Analisando e estruturando requisitos",
                "agent": self.agents["refiner"]
            },
            {
                "id": "selector", 
                "name": "ðŸŽ¯ Agente Seletor",
                "description": "Identificando templates adequados",
                "agent": self.agents["selector"]
            },
            {
                "id": "developer",
                "name": "ðŸ‘¨â€ðŸ’» Agente Desenvolvedor", 
                "description": "Gerando cÃ³digo ABAP",
                "agent": self.agents["developer"]
            },
            {
                "id": "reviewer",
                "name": "ðŸ” Agente Revisor",
                "description": "Revisando e otimizando cÃ³digo",
                "agent": self.agents["reviewer"]
            }
        ]
    
    def execute_pipeline(self, user_prompt: str, generation_type: str, 
                        prompt_file_path: str = None) -> Dict[str, Any]:
        """Executa pipeline completo de geraÃ§Ã£o"""
        
        print_colored("\n" + "="*70, "cyan")
        print_colored("ðŸš€ INICIANDO PIPELINE DE AGENTES ABAPFY", "cyan", bold=True)
        print_colored("="*70, "cyan")
        
        # Dados inicial
        pipeline_data = {
            "user_prompt": user_prompt,
            "generation_type": generation_type,
            "prompt_file_path": prompt_file_path
        }
        
        results = {}
        
        # Executar cada etapa do pipeline
        for i, step in enumerate(self.pipeline_steps, 1):
            step_id = step["id"]
            step_name = step["name"] 
            step_description = step["description"]
            agent = step["agent"]
            
            # Header da etapa
            print_colored(f"\nðŸ“‹ ETAPA {i}/4: {step_name}", "yellow", bold=True)
            print_colored(f"ðŸ“ {step_description}", "white")
            print_colored("-" * 50, "yellow")
            
            try:
                with LoadingContext(step_description, "spinner") as loader:
                    # Simular tempo de processamento
                    time.sleep(1)
                    
                    # Executar agente
                    step_result = agent.execute(pipeline_data)
                    
                    # Armazenar resultado
                    results[step_id] = step_result
                    
                    # Passar dados para prÃ³xima etapa
                    pipeline_data.update(step_result)
                
                # Mostrar resultado da etapa
                self._display_step_result(step_id, step_result)
                
            except Exception as e:
                print_colored(f"âŒ Erro na etapa {step_name}: {str(e)}", "red")
                raise
        
        # Resultado final
        self._display_final_result(results)
        
        return results
    
    def _display_step_result(self, step_id: str, result: Dict[str, Any]):
        """Exibe resultado de uma etapa especÃ­fica"""
        
        if step_id == "refiner":
            complexity = result.get("complexity_score", 0)
            templates_suggested = len(result.get("suggested_templates", []))
            
            print_colored(f"âœ… Prompt refinado com sucesso", "green")
            print_colored(f"ðŸ“Š Complexidade: {complexity}/10", "white")
            print_colored(f"ðŸŽ¯ Templates sugeridos: {templates_suggested}", "white")
            
        elif step_id == "selector":
            selected = result.get("selected_template")
            fallback = result.get("fallback_strategy", "")
            
            if selected:
                print_colored(f"âœ… Template selecionado: {selected['name']}", "green")
                print_colored(f"ðŸ“ˆ Score de compatibilidade: {selected.get('match_score', 0)}", "white")
            else:
                print_colored(f"ðŸ”„ EstratÃ©gia: {fallback}", "yellow")
                
        elif step_id == "developer":
            notes_count = len(result.get("implementation_notes", []))
            deps_count = len(result.get("dependencies", []))
            
            print_colored(f"âœ… CÃ³digo gerado com sucesso", "green") 
            print_colored(f"ðŸ“ Notas de implementaÃ§Ã£o: {notes_count}", "white")
            print_colored(f"ðŸ”— DependÃªncias identificadas: {deps_count}", "white")
            
        elif step_id == "reviewer":
            quality_score = result.get("quality_score", 0)
            corrections = len(result.get("corrections_made", []))
            
            print_colored(f"âœ… RevisÃ£o concluÃ­da", "green")
            print_colored(f"â­ Score de qualidade: {quality_score}/100", "white")
            print_colored(f"ðŸ”§ CorreÃ§Ãµes aplicadas: {corrections}", "white")
    
    def _display_final_result(self, results: Dict[str, Any]):
        """Exibe resultado final consolidado"""
        
        print_colored("\n" + "="*70, "green")
        print_colored("ðŸŽ‰ PIPELINE CONCLUÃDO COM SUCESSO!", "green", bold=True)
        print_colored("="*70, "green")
        
        # EstatÃ­sticas gerais
        final_code = results["reviewer"]["reviewed_code"]
        quality_score = results["reviewer"]["quality_score"]
        complexity = results["refiner"]["complexity_score"]
        
        print_colored(f"ðŸ“Š ESTATÃSTICAS FINAIS:", "cyan", bold=True)
        print_colored(f"  ðŸ“ Linhas de cÃ³digo: {len(final_code.splitlines())}", "white")
        print_colored(f"   â­ Score de qualidade: {quality_score}/100", "white")
        print_colored(f"   ðŸ§® Complexidade: {complexity}/10", "white")
        
        # Template usado
        selected_template = results["selector"].get("selected_template")
        if selected_template:
            print_colored(f"   ðŸŽ¯ Template utilizado: {selected_template['name']}", "white")
        else:
            print_colored(f"   ðŸ†• Desenvolvimento from scratch", "white")
        
        # CorreÃ§Ãµes aplicadas
        corrections = results["reviewer"]["corrections_made"]
        if corrections:
            print_colored(f"\nðŸ”§ CORREÃ‡Ã•ES APLICADAS:", "yellow", bold=True)
            for i, correction in enumerate(corrections[:3], 1):
                print_colored(f"   {i}. {correction.get('issue', 'CorreÃ§Ã£o aplicada')}", "white")
            if len(corrections) > 3:
                print_colored(f"   ... e mais {len(corrections)-3} correÃ§Ãµes", "yellow")
        
        # PrÃ³ximos passos
        next_steps = results["developer"]["next_steps"]
        if next_steps:
            print_colored(f"\nðŸ“‹ PRÃ“XIMOS PASSOS:", "magenta", bold=True)
            for i, step in enumerate(next_steps[:3], 1):
                print_colored(f"   {i}. {step}", "white")