# abapfy/analyzers/debugger.py
from typing import List, Dict, Any, Optional
from abapfy.embeddings.manager import EmbeddingManager
from abapfy.embeddings.chunker import ABAPCodeChunker, CodeChunk
from abapfy.ai.client import AIClient
from abapfy.config.manager import ConfigManager

class ABAPDebugger:
    """Analisador de debug para c√≥digo ABAP usando embeddings"""
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self.ai_client = AIClient(config)
        self.embedding_manager = EmbeddingManager()
        self.chunker = ABAPCodeChunker()
        
        # Padr√µes comuns de erro em ABAP
        self.error_patterns = {
            "runtime_errors": [
                "division by zero",
                "array index out of bounds", 
                "null pointer reference",
                "type conversion error",
                "memory allocation failed"
            ],
            "syntax_errors": [
                "missing ENDIF statement",
                "unmatched parentheses",
                "undefined variable reference",
                "invalid field assignment",
                "missing ENDLOOP statement"
            ],
            "logic_errors": [
                "infinite loop condition",
                "wrong variable assignment",
                "incorrect condition logic",
                "missing initialization",
                "unreachable code block"
            ],
            "database_errors": [
                "table not found",
                "field not found in table",
                "authorization error database",
                "transaction deadlock",
                "connection timeout"
            ]
        }
    
    def analyze_code_for_debug(self, file_path: str, 
                              error_description: Optional[str] = None,
                              error_location: Optional[str] = None) -> Dict[str, Any]:
        """Analisa c√≥digo ABAP para debug com contexto do erro"""
        try:
            # Ler arquivo
            with open(file_path, 'r', encoding='utf-8') as f:
                code_content = f.read()
            
            if not code_content.strip():
                raise ValueError("Arquivo est√° vazio")
            
            # Dividir c√≥digo em chunks
            chunks = self.chunker.chunk_code(code_content)
            
            # Criar embeddings
            chunk_texts = [chunk.content for chunk in chunks]
            content_hash = self.embedding_manager.calculate_content_hash(code_content)
            
            # Verificar cache
            chunk_embeddings = self.embedding_manager.get_cached_embeddings(content_hash)
            if chunk_embeddings is None:
                chunk_embeddings = self.embedding_manager.create_embeddings(chunk_texts)
                self.embedding_manager.cache_embeddings(content_hash, chunk_embeddings)
            
            # An√°lise baseada em padr√µes de erro
            error_analysis = self._analyze_error_patterns(chunk_texts, chunk_embeddings)
            
            # An√°lise contextual se erro foi fornecido
            contextual_analysis = {}
            if error_description:
                contextual_analysis = self._analyze_specific_error(
                    error_description, error_location, chunks, chunk_embeddings, chunk_texts
                )
            
            # Gerar an√°lise detalhada com IA
            detailed_debug = self._generate_detailed_debug_analysis(
                chunks, error_analysis, contextual_analysis, error_description
            )
            
            # Criar relat√≥rio de debug
            debug_report = self._create_debug_report(
                file_path, chunks, error_analysis, contextual_analysis, 
                detailed_debug, error_description, error_location
            )
            
            return debug_report
            
        except Exception as e:
            raise RuntimeError(f"Erro na an√°lise de debug: {str(e)}")
    
    def _analyze_error_patterns(self, chunk_texts: List[str], 
                               chunk_embeddings) -> Dict[str, Any]:
        """Analisa c√≥digo procurando padr√µes de erro conhecidos"""
        pattern_analysis = {}
        
        for error_type, patterns in self.error_patterns.items():
            # Criar embedding para padr√µes deste tipo de erro
            pattern_embedding = self.embedding_manager.create_embeddings(patterns)[0]
            
            # Encontrar chunks similares
            similar_chunks = self.embedding_manager.find_similar_chunks(
                pattern_embedding, chunk_embeddings, chunk_texts, top_k=5
            )
            
            # Filtrar apenas chunks com similaridade significativa
            significant_chunks = [(chunk, score) for chunk, score in similar_chunks if score > 0.25]
            
            pattern_analysis[error_type] = {
                'potential_issues': significant_chunks,
                'risk_level': len(significant_chunks)
            }
        
        return pattern_analysis
    
    def _analyze_specific_error(self, error_description: str, error_location: Optional[str],
                               chunks: List[CodeChunk], chunk_embeddings, 
                               chunk_texts: List[str]) -> Dict[str, Any]:
        """Analisa c√≥digo focando no erro espec√≠fico relatado"""
        # Criar embedding da descri√ß√£o do erro
        error_embedding = self.embedding_manager.create_embeddings([error_description])[0]
        
        # Encontrar chunks mais relacionados ao erro
        related_chunks = self.embedding_manager.find_similar_chunks(
            error_embedding, chunk_embeddings, chunk_texts, top_k=3
        )
        
        # Se localiza√ß√£o foi fornecida, dar prioridade a chunks naquela regi√£o
        if error_location:
            try:
                # Extrair n√∫mero da linha se fornecido
                line_numbers = [int(s) for s in error_location.split() if s.isdigit()]
                if line_numbers:
                    target_line = line_numbers[0]
                    
                    # Encontrar chunk que cont√©m a linha
                    target_chunks = []
                    for i, chunk in enumerate(chunks):
                        if chunk.start_line <= target_line <= chunk.end_line:
                            target_chunks.append((chunk_texts[i], 1.0))  # M√°xima relev√¢ncia
                            break
                    
                    if target_chunks:
                        related_chunks = target_chunks + related_chunks
            except:
                pass
        
        return {
            'error_description': error_description,
            'error_location': error_location,
            'related_chunks': related_chunks,
            'confidence_score': max([score for _, score in related_chunks]) if related_chunks else 0
        }
    
    def _generate_detailed_debug_analysis(self, chunks: List[CodeChunk], 
                                        error_analysis: Dict, 
                                        contextual_analysis: Dict,
                                        error_description: Optional[str]) -> Dict[str, str]:
        """Gera an√°lise detalhada usando IA"""
        detailed_analysis = {}
        
        # Coletar chunks mais problem√°ticos
        problematic_chunks = set()
        
        # Adicionar chunks da an√°lise de padr√µes
        for error_type, analysis in error_analysis.items():
            for chunk_content, score in analysis['potential_issues']:
                if score > 0.3:
                    problematic_chunks.add(chunk_content)
        
        # Adicionar chunks da an√°lise contextual
        if contextual_analysis.get('related_chunks'):
            for chunk_content, score in contextual_analysis['related_chunks']:
                if score > 0.4:
                    problematic_chunks.add(chunk_content)
        
        # Analisar chunks mais relevantes com IA
        for chunk_content in list(problematic_chunks)[:3]:  # Limitar a 3 chunks
            try:
                # Criar contexto espec√≠fico para debug
                debug_context = f"""
CONTEXTO DO DEBUG:
- Erro reportado: {error_description or 'An√°lise geral de debug'}
- Chunk analisado: {chunk_content[:200]}...

Analise este c√≥digo ABAP buscando:
1. Poss√≠veis causas do erro
2. Pontos de falha
3. Vari√°veis n√£o inicializadas
4. L√≥gica incorreta
5. Sugest√µes de corre√ß√£o
"""
                
                chunk_debug = self.ai_client.debug_code(chunk_content + "\n\n" + debug_context)
                detailed_analysis[chunk_content[:100] + "..."] = chunk_debug
                
            except Exception:
                continue
        
        return detailed_analysis
    
    def _create_debug_report(self, file_path: str, chunks: List[CodeChunk],
                           error_analysis: Dict, contextual_analysis: Dict,
                           detailed_debug: Dict, error_description: Optional[str],
                           error_location: Optional[str]) -> Dict[str, Any]:
        """Cria relat√≥rio consolidado de debug"""
        
        # Calcular score de problemas potenciais
        total_issues = sum(
            analysis['risk_level'] for analysis in error_analysis.values()
        )
        
        confidence_score = contextual_analysis.get('confidence_score', 0) * 100
        
        # Determinar prioridade de debug
        if confidence_score > 70:
            debug_priority = "üî¥ ALTA - Erro localizado"
        elif confidence_score > 40:
            debug_priority = "üü† M√âDIA - √Årea suspeita identificada"
        elif total_issues > 5:
            debug_priority = "üü° BAIXA - M√∫ltiplos pontos de aten√ß√£o"
        else:
            debug_priority = "üü¢ BAIXA - Poucos problemas detectados"
        
        report = {
            "metadata": {
                "file_path": file_path,
                "error_description": error_description,
                "error_location": error_location,
                "total_lines": sum(chunk.end_line - chunk.start_line + 1 for chunk in chunks),
                "total_chunks": len(chunks),
                "analysis_timestamp": self._get_timestamp()
            },
            "debug_summary": {
                "debug_priority": debug_priority,
                "confidence_score": round(confidence_score, 2),
                "potential_issues_found": total_issues,
                "most_likely_cause": self._determine_likely_cause(error_analysis, contextual_analysis)
            },
            "error_pattern_analysis": error_analysis,
            "contextual_analysis": contextual_analysis,
            "detailed_debug_analysis": detailed_debug,
            "debug_suggestions": self._generate_debug_suggestions(error_analysis, contextual_analysis),
            "next_steps": self._generate_next_steps(error_analysis, contextual_analysis, error_description)
        }
        
        return report
    
    def _determine_likely_cause(self, error_analysis: Dict, contextual_analysis: Dict) -> str:
        """Determina a causa mais prov√°vel baseada na an√°lise"""
        if contextual_analysis.get('confidence_score', 0) > 0.6:
            return "Erro espec√≠fico localizado com alta confian√ßa"
        
        # Encontrar tipo de erro com mais ocorr√™ncias
        max_risk = 0
        likely_cause = "N√£o determinado"
        
        for error_type, analysis in error_analysis.items():
            if analysis['risk_level'] > max_risk:
                max_risk = analysis['risk_level']
                likely_cause = error_type.replace('_', ' ').title()
        
        if max_risk > 0:
            return f"Poss√≠vel {likely_cause}"
        
        return "C√≥digo aparenta estar correto - verificar dados de entrada"
    
    def _generate_debug_suggestions(self, error_analysis: Dict, contextual_analysis: Dict) -> List[str]:
        """Gera sugest√µes espec√≠ficas para debug"""
        suggestions = []
        
        # Sugest√µes baseadas em padr√µes detectados
        for error_type, analysis in error_analysis.items():
            if analysis['risk_level'] > 0:
                if error_type == "runtime_errors":
                    suggestions.append("üîç Adicione verifica√ß√µes de divis√£o por zero e valida√ß√£o de arrays")
                elif error_type == "syntax_errors":
                    suggestions.append("üìù Verifique estruturas de controle (IF/ENDIF, LOOP/ENDLOOP)")
                elif error_type == "logic_errors":
                    suggestions.append("üß† Revise condi√ß√µes de loop e inicializa√ß√£o de vari√°veis")
                elif error_type == "database_errors":
                    suggestions.append("üíæ Verifique permiss√µes e exist√™ncia de tabelas/campos")
        
        if contextual_analysis.get('confidence_score', 0) > 0.5:
            suggestions.append("üéØ Foque na an√°lise detalhada dos chunks identificados")
            suggestions.append("üîß Execute debug passo-a-passo na √°rea suspeita")
        
        if not suggestions:
            suggestions.append("‚úÖ Execute testes unit√°rios para validar comportamento")
            suggestions.append("üìä Adicione logs detalhados para rastreamento")
        
        return suggestions
    
    def _generate_next_steps(self, error_analysis: Dict, contextual_analysis: Dict,
                            error_description: Optional[str]) -> List[str]:
        """Gera pr√≥ximos passos para resolu√ß√£o"""
        next_steps = []
        
        if error_description:
            next_steps.append("1. üîç Execute o c√≥digo com debugger na √°rea identificada")
            next_steps.append("2. üìù Valide valores de vari√°veis nos pontos suspeitos")
            next_steps.append("3. üß™ Teste com dados diferentes para reproduzir o erro")
        else:
            next_steps.append("1. üß™ Execute testes com casos extremos")
            next_steps.append("2. üìä Adicione logs em pontos cr√≠ticos")
            next_steps.append("3. üîç Monitore performance e uso de mem√≥ria")
        
        next_steps.append("4. üìã Implemente melhorias sugeridas na an√°lise")
        next_steps.append("5. ‚úÖ Execute bateria de testes ap√≥s corre√ß√µes")
        
        return next_steps
    
    def _get_timestamp(self) -> str:
        """Obt√©m timestamp atual"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")